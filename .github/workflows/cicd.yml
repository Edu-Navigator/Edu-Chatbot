# cicd.yml

name: Airflow DAG CI/CD

on:
  push:
    branches: [ main, 'feature/**' ]
  pull_request:
    branches: [ main ]

jobs:
  dag-test:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.10"

      - name: Install Ruff
        run: |
          pip install ruff

      - name: Run Ruff lint
        continue-on-error: true
        run: |
          ruff check .

      - name: Run Ruff format check
        continue-on-error: true
        run: |
          ruff format --check .

      - name: Run Airflow DAG import test
        run: |
          docker compose -f docker-compose.ci.yml up \
            --build \
            --abort-on-container-exit \
            --exit-code-from airflow-test

      - name: Show Docker logs on failure
        if: failure()
        run: |
          docker compose -f docker-compose.ci.yml logs

  # main ë¸Œëœì¹˜ì— pushë  ë•Œë§Œ ë°°í¬
  deploy-to-s3:
    needs: dag-test
    if: github.ref == 'refs/heads/main' && github.event_name == 'push'
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
    
    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v4
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: ${{ vars.AWS_REGION }}

    - name: Sync to S3
      run: |
        # DAGsë§Œ ì—…ë¡œë“œ
        aws s3 sync ./airflow/dags/ s3://${{ vars.S3_BUCKET_NAME }}/airflow/dags/ \
          --exclude ".git/*" \
          --exclude ".github/*" \
          --exclude "*.md" \
          --exclude "docker-compose*.yml" \
          --exclude "Dockerfile" \
          --exclude "*.pyc" \
          --exclude "__pycache__/*" \
          --delete
        echo "âœ… S3 ì—…ë¡œë“œ ì™„ë£Œ"
    
  # Self-hosted runnerë¡œ Main ì„œë²„ ë°°í¬
  deploy-to-main:
    needs: deploy-to-s3
    runs-on: [self-hosted, airflow-main]
    
    steps:
    - name: Sync DAGs from S3
      run: |
        echo "ğŸš€ Airflow Main ë°°í¬ ì‹œì‘..."
        
        # S3ì—ì„œ DAGs ë™ê¸°í™”
        aws s3 sync s3://${{ vars.S3_BUCKET_NAME }}/airflow/dags/ \
          /home/ubuntu/airflow/dags/ \
          --delete
        
        echo "âœ… DAGs ë™ê¸°í™” ì™„ë£Œ"
    
    - name: Restart Airflow services
      run: |
        echo "ğŸ”„ Airflow ì„œë¹„ìŠ¤ ì¬ì‹œì‘..."
        sudo systemctl restart airflow-webserver
        sudo systemctl restart airflow-scheduler
        
        # ì„œë¹„ìŠ¤ ì‹œì‘ ëŒ€ê¸°
        sleep 5
        
        # ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸
        if sudo systemctl is-active --quiet airflow-webserver && \
           sudo systemctl is-active --quiet airflow-scheduler; then
          echo "âœ… Airflow Main ë°°í¬ ì™„ë£Œ"
        else
          echo "âŒ Airflow ì„œë¹„ìŠ¤ ì‹œì‘ ì‹¤íŒ¨"
          sudo systemctl status airflow-webserver || true
          sudo systemctl status airflow-scheduler || true
          exit 1
        fi

  # Self-hosted runnerë¡œ Worker ì„œë²„ ë°°í¬
  deploy-to-worker:
    needs: deploy-to-main
    runs-on: [self-hosted, airflow-worker]

    steps:
    - name: Sync DAGs from S3
      run: |
        echo "ğŸš€ Airflow Worker ë°°í¬ ì‹œì‘..."
        
        # S3ì—ì„œ DAGs ë™ê¸°í™”
        aws s3 sync s3://${{ vars.S3_BUCKET_NAME }}/airflow/dags/ \
          /home/ubuntu/airflow/dags/ \
          --delete
        
        echo "âœ… DAGs ë™ê¸°í™” ì™„ë£Œ"
    
    - name: Restart Airflow worker
      run: |
        echo "ğŸ”„ Airflow Worker ì¬ì‹œì‘..."
        sudo systemctl restart airflow-worker
        
        # ì„œë¹„ìŠ¤ ì‹œì‘ ëŒ€ê¸°
        sleep 5
        
        # ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸
        if sudo systemctl is-active --quiet airflow-worker; then
          echo "âœ… Airflow Worker ë°°í¬ ì™„ë£Œ"
        else
          echo "âŒ Airflow Worker ì‹œì‘ ì‹¤íŒ¨"
          sudo systemctl status airflow-worker || true
          exit 1
        fi

  # ë°°í¬ ì™„ë£Œ ì•Œë¦¼
  notify-deployment:
    needs: [deploy-to-main, deploy-to-worker]
    if: success()
    runs-on: ubuntu-latest
    
    steps:
    - name: Deployment Success
      run: |
        echo "ğŸ‰ ë°°í¬ ì™„ë£Œ!"
        echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
        echo "ğŸ“¦ S3 Bucket: ${{ vars.S3_BUCKET_NAME }}"
        echo "ğŸ–¥ï¸  Airflow Main: team7-airflow-main"
        echo "âš™ï¸  Airflow Worker: team7-airflow-worker"
        echo "ğŸ• Deployed at: $(date '+%Y-%m-%d %H:%M:%S')"
        echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"