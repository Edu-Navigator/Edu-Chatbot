# cicd.yml

name: Airflow DAG CI/CD

on:
  push:
    branches: [ main, 'feature/**' ]
  pull_request:
    branches: [ main ]

jobs:
  dag-test:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.10"

      - name: Install Ruff
        run: |
          pip install ruff

      - name: Run Ruff lint
        continue-on-error: true
        run: |
          ruff check .

      - name: Run Ruff format check
        continue-on-error: true
        run: |
          ruff format --check .

      - name: Run Airflow DAG import test
        run: |
          docker compose -f docker-compose.ci.yml up \
            --build \
            --abort-on-container-exit \
            --exit-code-from airflow-test

      - name: Show Docker logs on failure
        if: failure()
        run: |
          docker compose -f docker-compose.ci.yml logs

  # main ë¸Œëœì¹˜ì— pushë  ë•Œë§Œ ë°°í¬
  deploy-to-s3:
    needs: dag-test
    if: github.ref == 'refs/heads/main' && github.event_name == 'push'
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
    
    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v4
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: ${{ vars.AWS_REGION }}

    - name: Sync to S3
      run: |
        # DAGsë§Œ ì—…ë¡œë“œ
        aws s3 sync ./airflow/dags/ s3://${{ vars.S3_BUCKET_NAME }}airflow/dags/ \
          --exclude ".git/*" \
          --exclude ".github/*" \
          --exclude "*.md" \
          --exclude "docker-compose*.yml" \
          --exclude "Dockerfile" \
          --exclude "*.pyc" \
          --exclude "__pycache__/*" \
          --delete
        echo "âœ… S3 ì—…ë¡œë“œ ì™„ë£Œ"
    
  deploy-to-main:
    needs: deploy-to-s3
    runs-on: [self-hosted, airflow-main]
    
    steps:
    - name: Clean pycache
      run: |
        sudo find /home/ubuntu/airflow/dags -type d -name "__pycache__" -exec rm -rf {} +

    - name: Sync DAGs from S3
      run: |
        echo "ğŸš€ Airflow Main ë°°í¬ ì‹œì‘..."
        aws s3 sync s3://${{ vars.S3_BUCKET_NAME }}/airflow/dags/ \
          /home/ubuntu/airflow/dags/ \
          --delete \
          --exclude "__pycache__/*" \
          --exclude "**/__pycache__/*" \
          --exclude "*.pyc"
        echo "âœ… DAGs ë™ê¸°í™” ì™„ë£Œ"

    - name: Restart Airflow (manual)
      run: |
        echo "ğŸ”„ Airflow processes ì¬ì‹œì‘ì¤‘..."

        pkill -f "airflow webserver" || true
        pkill -f "airflow scheduler" || true
        pkill -f "airflow triggerer" || true

        sleep 3

        nohup /home/airflow/.local/bin/airflow scheduler > ~/airflow-scheduler.log 2>&1 &
        nohup /home/airflow/.local/bin/airflow webserver > ~/airflow-webserver.log 2>&1 &
        nohup /home/airflow/.local/bin/airflow triggerer > ~/airflow-triggerer.log 2>&1 &

        echo "âœ… Airflow Main ë°°í¬ ì™„ë£Œ"


  # Self-hosted runnerë¡œ Worker ì„œë²„ ë°°í¬
  deploy-to-worker:
    needs: deploy-to-main
    runs-on: [self-hosted, airflow-worker]

    steps:
    
    - name: Clean pycache
      run: |
        sudo find /home/ubuntu/airflow/dags -type d -name "__pycache__" -exec rm -rf {} +

    - name: Sync DAGs from S3
      run: |
        echo "ğŸš€ Airflow Worker ë°°í¬ ì‹œì‘..."
        
        # S3ì—ì„œ DAGs ë™ê¸°í™”
        aws s3 sync s3://${{ vars.S3_BUCKET_NAME }}/airflow/dags/ \
          /home/ubuntu/airflow/dags/ \
        --delete \
        --exclude "__pycache__/*" \
        --exclude "**/__pycache__/*" \
        --exclude "*.pyc"
      
        echo "âœ… DAGs ë™ê¸°í™” ì™„ë£Œ"
    
    - name: Restart Airflow (manual)
      run: |
        echo "ğŸ”„ Airflow processes ì¬ì‹œì‘ì¤‘..."

        pkill -f "airflow webserver" || true
        pkill -f "airflow scheduler" || true
        pkill -f "airflow triggerer" || true

        sleep 3

        nohup /home/airflow/.local/bin/airflow scheduler > ~/airflow-scheduler.log 2>&1 &
        nohup /home/airflow/.local/bin/airflow webserver > ~/airflow-webserver.log 2>&1 &
        nohup /home/airflow/.local/bin/airflow triggerer > ~/airflow-triggerer.log 2>&1 &

        echo "âœ… Airflow ë°°í¬ ì™„ë£Œ"


  # ë°°í¬ ì™„ë£Œ ì•Œë¦¼
  notify-deployment:
    needs: [deploy-to-main, deploy-to-worker]
    if: success()
    runs-on: ubuntu-latest
    
    steps:
    - name: Deployment Success
      run: |
        echo "ğŸ‰ ë°°í¬ ì™„ë£Œ!"
        echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
        echo "ğŸ“¦ S3 Bucket: ${{ vars.S3_BUCKET_NAME }}"
        echo "ğŸ–¥ï¸  Airflow Main: team7-airflow-main"
        echo "âš™ï¸  Airflow Worker: team7-airflow-worker"
        echo "ğŸ• Deployed at: $(date '+%Y-%m-%d %H:%M:%S')"
        echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"

  # ë°°í¬ ì‹¤íŒ¨ ì‹œ ì‘ì„±ìì—ê²Œ ì´ë©”ì¼ ì•Œë¦¼
  notify-failure:
    needs: [deploy-to-main, deploy-to-worker]
    if: failure()
    runs-on: ubuntu-latest

    steps:
    - name: Get PR author from merge commit
      id: pr-author
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
      run: |
        PR_NUMBER=$(echo "${{ github.event.head_commit.message }}" | grep -oE '#[0-9]+' | tr -d '#')

        if [ -z "$PR_NUMBER" ]; then
          echo "PR ë²ˆí˜¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
          exit 0
        fi

        AUTHOR=$(curl -s \
          -H "Authorization: token $GITHUB_TOKEN" \
          -H "Accept: application/vnd.github+json" \
          https://api.github.com/repos/${{ github.repository }}/pulls/$PR_NUMBER \
          | jq -r '.user.login')

        echo "author=$AUTHOR" >> $GITHUB_OUTPUT

    - name: Get PR author email
      id: get-email
      run: |
        EMAIL=$(echo '${{ secrets.EMAIL_MAPPING }}' | jq -r '.["${{ steps.pr-author.outputs.author }}"] // empty')
        echo "email=$EMAIL" >> $GITHUB_OUTPUT

    - name: Send failure email to PR author
      if: steps.get-email.outputs.email != ''
      uses: dawidd6/action-send-mail@v3
      with:
        server_address: smtp.gmail.com
        server_port: 587
        username: ${{ secrets.EMAIL_USERNAME }}
        password: ${{ secrets.EMAIL_PASSWORD }}
        subject: "[Airflow CD] ë°°í¬ ì‹¤íŒ¨ ì•Œë¦¼"
        to: ${{ steps.get-email.outputs.email }}
        from: GitHub Actions
        body: |
          ì•ˆë…•í•˜ì„¸ìš” ${{ steps.pr-author.outputs.author }}ë‹˜,
          ...
          ë³¸ì¸ì´ ìƒì„±í•œ PRì´ mainì— mergeëœ ì´í›„
          Airflow CD ë°°í¬ ê³¼ì •ì—ì„œ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.

          â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
           ì‹¤íŒ¨ ì •ë³´
          â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
          â€¢ Repository : ${{ github.repository }}
          â€¢ Commit SHA : ${{ github.sha }}
          â€¢ Commit Msg : ${{ github.event.head_commit.message }}
          â€¢ Failed Job : ${{ github.job }}
          â€¢ Run ID     : ${{ github.run_id }}

           ì‹¤íŒ¨ ë¡œê·¸ ë°”ë¡œê°€ê¸°
          ${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}

          â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
          í™•ì¸ ë¶€íƒë“œë¦½ë‹ˆë‹¤.